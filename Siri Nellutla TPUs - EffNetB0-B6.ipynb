{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIRI NELLUTLA - Kaggle\n",
    "# TPUs - finetune EffNetB0-B6 \n",
    "### Following notebook uses:\n",
    "* Tensorflow and TPUs\n",
    "* 224x224 sized pretrained EfficientNetB0 to B6 combined into one huge model -> Total params: 116,336,013 (!!) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"TPU\"\n",
    "\n",
    "CFG = dict(\n",
    "    net_count         =   7,\n",
    "    batch_size        =  16,\n",
    "    \n",
    "    read_size         = 256, \n",
    "    crop_size         = 250, \n",
    "    net_size          = 224, \n",
    "    \n",
    "    LR_START          =   0.000005,\n",
    "    LR_MAX            =   0.000020,\n",
    "    LR_MIN            =   0.000001,\n",
    "    LR_RAMPUP_EPOCHS  =   5,\n",
    "    LR_SUSTAIN_EPOCHS =   0,\n",
    "    LR_EXP_DECAY      =   0.8,\n",
    "    epochs            =  12,\n",
    "    \n",
    "    rot               = 180.0,\n",
    "    shr               =   2.0,\n",
    "    hzoom             =   8.0,\n",
    "    wzoom             =   8.0,\n",
    "    hshift            =   8.0,\n",
    "    wshift            =   8.0,\n",
    "\n",
    "    optimizer         = 'adam',\n",
    "    label_smooth_fac  =   0.05,\n",
    "    \n",
    "    tta_steps         =  25    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "if DEVICE == \"TPU\":\n",
    "    print(\"connecting to TPU...\")\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        print('Running on TPU ', tpu.master())\n",
    "    except ValueError:\n",
    "        print(\"Could not connect to TPU\")\n",
    "        tpu = None\n",
    "\n",
    "    if tpu:\n",
    "        try:\n",
    "            print(\"initializing  TPU ...\")\n",
    "            tf.config.experimental_connect_to_cluster(tpu)\n",
    "            tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "            print(\"TPU initialized\")\n",
    "        except _:\n",
    "            print(\"failed to initialize TPU\")\n",
    "    else:\n",
    "        DEVICE = \"GPU\"\n",
    "\n",
    "if DEVICE != \"TPU\":\n",
    "    print(\"Using default strategy for CPU and single GPU\")\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "if DEVICE == \"GPU\":\n",
    "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "    \n",
    "\n",
    "AUTO     = tf.data.experimental.AUTOTUNE\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "print(f'REPLICAS: {REPLICAS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n",
    "    # returns 3x3 transformmatrix which transforms indicies\n",
    "        \n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.\n",
    "    shear    = math.pi * shear    / 180.\n",
    "\n",
    "    def get_3x3_mat(lst):\n",
    "        return tf.reshape(tf.concat([lst],axis=0), [3,3])\n",
    "    \n",
    "    # ROTATION MATRIX\n",
    "    c1   = tf.math.cos(rotation)\n",
    "    s1   = tf.math.sin(rotation)\n",
    "    one  = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    \n",
    "    rotation_matrix = get_3x3_mat([c1,   s1,   zero, \n",
    "                                   -s1,  c1,   zero, \n",
    "                                   zero, zero, one])    \n",
    "    # SHEAR MATRIX\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)    \n",
    "    \n",
    "    shear_matrix = get_3x3_mat([one,  s2,   zero, \n",
    "                                zero, c2,   zero, \n",
    "                                zero, zero, one])        \n",
    "    # ZOOM MATRIX\n",
    "    zoom_matrix = get_3x3_mat([one/height_zoom, zero,           zero, \n",
    "                               zero,            one/width_zoom, zero, \n",
    "                               zero,            zero,           one])    \n",
    "    # SHIFT MATRIX\n",
    "    shift_matrix = get_3x3_mat([one,  zero, height_shift, \n",
    "                                zero, one,  width_shift, \n",
    "                                zero, zero, one])\n",
    "    \n",
    "    return K.dot(K.dot(rotation_matrix, shear_matrix), \n",
    "                 K.dot(zoom_matrix,     shift_matrix))\n",
    "\n",
    "\n",
    "def transform(image, cfg):    \n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly rotated, sheared, zoomed, and shifted\n",
    "    DIM = cfg[\"read_size\"]\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    rot = cfg['rot'] * tf.random.normal([1], dtype='float32')\n",
    "    shr = cfg['shr'] * tf.random.normal([1], dtype='float32') \n",
    "    h_zoom = 1.0 + tf.random.normal([1], dtype='float32') / cfg['hzoom']\n",
    "    w_zoom = 1.0 + tf.random.normal([1], dtype='float32') / cfg['wzoom']\n",
    "    h_shift = cfg['hshift'] * tf.random.normal([1], dtype='float32') \n",
    "    w_shift = cfg['wshift'] * tf.random.normal([1], dtype='float32') \n",
    "\n",
    "    # GET TRANSFORMATION MATRIX\n",
    "    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x   = tf.repeat(tf.range(DIM//2, -DIM//2,-1), DIM)\n",
    "    y   = tf.tile(tf.range(-DIM//2, DIM//2), [DIM])\n",
    "    z   = tf.ones([DIM*DIM], dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(m, tf.cast(idx, dtype='float32'))\n",
    "    idx2 = K.cast(idx2, dtype='int32')\n",
    "    idx2 = K.clip(idx2, -DIM//2+XDIM+1, DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES           \n",
    "    idx3 = tf.stack([DIM//2-idx2[0,], DIM//2-1+idx2[1,]])\n",
    "    d    = tf.gather_nd(image, tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d,[DIM, DIM,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labeled_tfrecord(example):\n",
    "    tfrec_format = {\n",
    "        'image'                        : tf.io.FixedLenFeature([], tf.string),\n",
    "        'image_name'                   : tf.io.FixedLenFeature([], tf.string),\n",
    "        'patient_id'                   : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'sex'                          : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'age_approx'                   : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'anatom_site_general_challenge': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'diagnosis'                    : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'target'                       : tf.io.FixedLenFeature([], tf.int64)\n",
    "    }           \n",
    "    example = tf.io.parse_single_example(example, tfrec_format)\n",
    "    return example['image'], example['target']\n",
    "\n",
    "\n",
    "def read_unlabeled_tfrecord(example, return_image_name):\n",
    "    tfrec_format = {\n",
    "        'image'                        : tf.io.FixedLenFeature([], tf.string),\n",
    "        'image_name'                   : tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrec_format)\n",
    "    return example['image'], example['image_name'] if return_image_name else 0\n",
    "\n",
    " \n",
    "def prepare_image(img, cfg=None, augment=True):    \n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [cfg['read_size'], cfg['read_size']])\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    \n",
    "    if augment:\n",
    "        img = transform(img, cfg)\n",
    "        img = tf.image.random_crop(img, [cfg['crop_size'], cfg['crop_size'], 3])\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_hue(img, 0.01)\n",
    "        img = tf.image.random_saturation(img, 0.7, 1.3)\n",
    "        img = tf.image.random_contrast(img, 0.8, 1.2)\n",
    "        img = tf.image.random_brightness(img, 0.1)\n",
    "\n",
    "    else:\n",
    "        img = tf.image.central_crop(img, cfg['crop_size'] / cfg['read_size'])\n",
    "                                   \n",
    "    img = tf.image.resize(img, [cfg['net_size'], cfg['net_size']])\n",
    "    img = tf.reshape(img, [cfg['net_size'], cfg['net_size'], 3])\n",
    "    return img\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) \n",
    "         for filename in filenames]\n",
    "    return np.sum(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(files, cfg, augment = False, shuffle = False, repeat = False, \n",
    "                labeled=True, return_image_names=True):\n",
    "    \n",
    "    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n",
    "    ds = ds.cache()\n",
    "    \n",
    "    if repeat:\n",
    "        ds = ds.repeat()\n",
    "    \n",
    "    if shuffle: \n",
    "        ds = ds.shuffle(1024*8)\n",
    "        opt = tf.data.Options()\n",
    "        opt.experimental_deterministic = False\n",
    "        ds = ds.with_options(opt)\n",
    "        \n",
    "    if labeled: \n",
    "        ds = ds.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n",
    "    else:\n",
    "        ds = ds.map(lambda example: read_unlabeled_tfrecord(example, return_image_names), \n",
    "                    num_parallel_calls=AUTO)      \n",
    "    \n",
    "    ds = ds.map(lambda img, imgname_or_label: (prepare_image(img, augment=augment, cfg=cfg), \n",
    "                                               imgname_or_label), \n",
    "                num_parallel_calls=AUTO)\n",
    "    \n",
    "    ds = ds.batch(cfg['batch_size'] * REPLICAS)\n",
    "    ds = ds.prefetch(AUTO)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dataset(thumb_size, cols, rows, ds):\n",
    "    mosaic = PIL.Image.new(mode='RGB', size=(thumb_size*cols + (cols-1), \n",
    "                                             thumb_size*rows + (rows-1)))\n",
    "   \n",
    "    for idx, data in enumerate(iter(ds)):\n",
    "        img, target_or_imgid = data\n",
    "        ix  = idx % cols\n",
    "        iy  = idx // cols\n",
    "        img = np.clip(img.numpy() * 255, 0, 255).astype(np.uint8)\n",
    "        img = PIL.Image.fromarray(img)\n",
    "        img = img.resize((thumb_size, thumb_size), resample=PIL.Image.BILINEAR)\n",
    "        mosaic.paste(img, (ix*thumb_size + ix, \n",
    "                           iy*thumb_size + iy))\n",
    "\n",
    "    display(mosaic)\n",
    "    \n",
    "ds = get_dataset(files_train, CFG).unbatch().take(12*5)   \n",
    "show_dataset(64, 12, 5, ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.TFRecordDataset(files_train, num_parallel_reads=AUTO)\n",
    "ds = ds.take(1).cache().repeat()\n",
    "ds = ds.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n",
    "ds = ds.map(lambda img, target: (prepare_image(img, cfg=CFG, augment=True), target), \n",
    "            num_parallel_calls=AUTO)\n",
    "ds = ds.take(12*5)\n",
    "ds = ds.prefetch(AUTO)\n",
    "\n",
    "show_dataset(64, 12, 5, ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images from the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = get_dataset(files_test, CFG, labeled=False).unbatch().take(12*5)   \n",
    "show_dataset(64, 12, 5, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_callback(cfg):\n",
    "    lr_start   = cfg['LR_START']\n",
    "    lr_max     = cfg['LR_MAX'] * strategy.num_replicas_in_sync\n",
    "    lr_min     = cfg['LR_MIN']\n",
    "    lr_ramp_ep = cfg['LR_RAMPUP_EPOCHS']\n",
    "    lr_sus_ep  = cfg['LR_SUSTAIN_EPOCHS']\n",
    "    lr_decay   = cfg['LR_EXP_DECAY']\n",
    "   \n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_ramp_ep:\n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "            \n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "            lr = lr_max\n",
    "            \n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "            \n",
    "        return lr\n",
    "\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n",
    "    return lr_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(cfg):\n",
    "    model_input = tf.keras.Input(shape=(cfg['net_size'], cfg['net_size'], 3), name='imgIn')\n",
    "\n",
    "    dummy = tf.keras.layers.Lambda(lambda x:x)(model_input)\n",
    "    \n",
    "    outputs = []    \n",
    "    for i in range(cfg['net_count']):\n",
    "        constructor = getattr(efn, f'EfficientNetB{i}')\n",
    "        \n",
    "        x = constructor(include_top=False, weights='imagenet', \n",
    "                        input_shape=(cfg['net_size'], cfg['net_size'], 3), \n",
    "                        pooling='avg')(dummy)\n",
    "        \n",
    "        x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "        outputs.append(x)\n",
    "        \n",
    "    model = tf.keras.Model(model_input, outputs, name='aNetwork')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_new_model(cfg):    \n",
    "    with strategy.scope():\n",
    "        model = get_model(cfg)\n",
    "     \n",
    "        losses = [tf.keras.losses.BinaryCrossentropy(label_smoothing = cfg['label_smooth_fac'])\n",
    "                  for i in range(cfg['net_count'])]\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer = cfg['optimizer'],\n",
    "            loss      = losses,\n",
    "            metrics   = [tf.keras.metrics.AUC(name='auc')])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train     = get_dataset(files_train, CFG, augment=True, shuffle=True, repeat=True)\n",
    "ds_train     = ds_train.map(lambda img, label: (img, tuple([label] * CFG['net_count'])))\n",
    "\n",
    "steps_train  = count_data_items(files_train) / (CFG['batch_size'] * REPLICAS)\n",
    "\n",
    "model        = compile_new_model(CFG)\n",
    "history      = model.fit(ds_train, \n",
    "                         verbose          = 1,\n",
    "                         steps_per_epoch  = steps_train, \n",
    "                         epochs           = CFG['epochs'],\n",
    "                         callbacks        = [get_lr_callback(CFG)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict the test set using augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG['batch_size'] = 256\n",
    "\n",
    "cnt_test   = count_data_items(files_test)\n",
    "steps      = cnt_test / (CFG['batch_size'] * REPLICAS) * CFG['tta_steps']\n",
    "ds_testAug = get_dataset(files_test, CFG, augment=True, repeat=True, \n",
    "                         labeled=False, return_image_names=False)\n",
    "\n",
    "probs = model.predict(ds_testAug, verbose=1, steps=steps)\n",
    "\n",
    "probs = np.stack(probs)\n",
    "probs = probs[:,:cnt_test * CFG['tta_steps']]\n",
    "probs = np.stack(np.split(probs, CFG['tta_steps'], axis=1), axis=1)\n",
    "probs = np.mean(probs, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = get_dataset(files_test, CFG, augment=False, repeat=False, \n",
    "                 labeled=False, return_image_names=True)\n",
    "\n",
    "image_names = np.array([img_name.numpy().decode(\"utf-8\") \n",
    "                        for img, img_name in iter(ds.unbatch())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write a submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(CFG[\"net_count\"]):\n",
    "    submission = pd.DataFrame(dict(\n",
    "        image_name = image_names,\n",
    "        target     = probs[i,:,0]))\n",
    "\n",
    "    submission = submission.sort_values('image_name') \n",
    "    submission.to_csv(f'submission_model_{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write a submission file using the mean of all submodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(dict(\n",
    "    image_name = image_names,\n",
    "    target     = np.mean(probs[:,:,0], axis=0)))\n",
    "\n",
    "submission = submission.sort_values('image_name') \n",
    "submission.to_csv('submission_models_blended.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p27",
   "language": "python",
   "name": "conda_amazonei_mxnet_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
